{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b819ec",
   "metadata": {},
   "source": [
    "# Classical Machine Learning Pipeline\n",
    "\n",
    "This section describes a classical machine learning pipeline.\n",
    "\n",
    "We leverage [MLUtils](https://github.com/JuliaML/MLUtils.jl), among the other things, for loading the data to play with, that is, the `iris` dataset.\n",
    "\n",
    "We partition the data into a set of *instances* `X` and the corresponding *labels* `y`. Each instance is one element of the cartesian product between the domains of the *attributes*.\n",
    "\n",
    "We want to find a relation between the instance space (i.e., many examples of iris flower) and the label space (i.e., the exact family to which each flower belongs). \n",
    "\n",
    "What we are going to do is train a (classification) decision tree, leveraging the `DecisionTree` library. \n",
    "\n",
    "Later in the notebook, we will repeat the process but leveraging `Sole.jl` library, and more-than-propositional logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197bfde",
   "metadata": {},
   "source": [
    "## Data Loading and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06522de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], [\"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\"  …  \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\"], [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MLUtils\n",
    "\n",
    "X, y = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5f9fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "500b76a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c45dce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 5.843333333333335\n",
       " 3.057333333333334\n",
       " 3.7580000000000027\n",
       " 1.199333333333334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2af98436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 0.8280661279778629\n",
       " 0.435866284936698\n",
       " 1.7652982332594664\n",
       " 0.7622376689603465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "473c4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 4.3\n",
       " 2.0\n",
       " 1.0\n",
       " 0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minimum(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74d331d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 7.9\n",
       " 4.4\n",
       " 6.9\n",
       " 2.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maximum(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac52333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa - 50\n",
      "versicolor - 50\n",
      "virginica - 50\n"
     ]
    }
   ],
   "source": [
    "for class in unique(y)\n",
    "    println(\"$(class) - $(count(yi -> yi == class, y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77c324",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In the limited scenario of this exercise, there is not much space for complex preprocessing of our data. For example, we are not dealing with unbalanced classes, missing data and complex encodings. \n",
    "\n",
    "In the cell below, we partition the data into a training and a testing bucket, keeping a balanced class diversity.\n",
    "\n",
    "With this distinction, we can train a model on the initial training data and leverage the testing one for simulating a real-world scenario, obtaining reliable performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566968c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "Random.seed!(1605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e2ae99c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.9 5.8 … 6.5 5.1; 3.1 2.7 … 3.0 2.5; 4.9 3.9 … 5.8 3.0; 1.5 1.2 … 2.2 1.1], [\"versicolor\", \"versicolor\", \"versicolor\", \"virginica\", \"setosa\", \"virginica\", \"setosa\", \"versicolor\", \"setosa\", \"virginica\"  …  \"virginica\", \"setosa\", \"setosa\", \"versicolor\", \"virginica\", \"setosa\", \"versicolor\", \"versicolor\", \"virginica\", \"versicolor\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at the next cell; do you see why we need to shuffle our instances here?\n",
    "Xs, ys = shuffleobs((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d01acdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([6.9 5.8 … 6.0 4.9; 3.1 2.7 … 2.7 3.0; 4.9 3.9 … 5.1 1.4; 1.5 1.2 … 1.6 0.2], [\"versicolor\", \"versicolor\", \"versicolor\", \"virginica\", \"setosa\", \"virginica\", \"setosa\", \"versicolor\", \"setosa\", \"virginica\"  …  \"virginica\", \"versicolor\", \"setosa\", \"virginica\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"versicolor\", \"setosa\"]), ([6.1 7.7 … 6.5 5.1; 2.9 2.8 … 3.0 2.5; 4.7 6.7 … 5.8 3.0; 1.4 2.0 … 2.2 1.1], [\"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"virginica\", \"versicolor\"  …  \"virginica\", \"setosa\", \"setosa\", \"versicolor\", \"virginica\", \"setosa\", \"versicolor\", \"versicolor\", \"virginica\", \"versicolor\"]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data, testing_data = splitobs((Xs, ys); at = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb0c99d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.1 7.7 … 6.5 5.1; 2.9 2.8 … 3.0 2.5; 4.7 6.7 … 5.8 3.0; 1.4 2.0 … 2.2 1.1], [\"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"virginica\", \"versicolor\"  …  \"virginica\", \"setosa\", \"setosa\", \"versicolor\", \"virginica\", \"setosa\", \"versicolor\", \"versicolor\", \"virginica\", \"versicolor\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = training_data\n",
    "X_test, y_test  = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4ec6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c7799ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aef71b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7910a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                5\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [\"setosa\", \"versicolor\", \"virginica\"]\n",
       "root:                     Decision Tree\n",
       "Leaves: 7\n",
       "Depth:  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DecisionTree\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth = 5,\n",
    "    min_samples_leaf = 1,\n",
    "    min_samples_split = 2\n",
    ")\n",
    "\n",
    "fit!(model, X_train', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a3f6b",
   "metadata": {},
   "source": [
    "When printing a decision tree with `DecisionTree.print_tree`, the $N \\setminus M$ to the right of a leaf $l$\n",
    "encodes the fact that $N$ instances respects all the condition from the root of the tree to $l$ and, among those, $M$ are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09f5dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3 < 2.6 ?\n",
      "├─ setosa : 42/42\n",
      "└─ Feature 4 < 1.75 ?\n",
      "    ├─ Feature 3 < 5.05 ?\n",
      "        ├─ versicolor : 35/35\n",
      "        └─ Feature 1 < 6.05 ?\n",
      "            ├─ versicolor : 1/1\n",
      "            └─ virginica : 3/3\n",
      "    └─ Feature 3 < 4.85 ?\n",
      "        ├─ Feature 2 < 3.1 ?\n",
      "            ├─ virginica : 2/2\n",
      "            └─ versicolor : 1/1\n",
      "        └─ virginica : 36/36\n"
     ]
    }
   ],
   "source": [
    "print_tree(model) # use print_tree(model, N) to limit the depth of the printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "89cc5388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{String}:\n",
       " \"versicolor\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"versicolor\"\n",
       " \"versicolor\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "y_pred = predict(model, X_test')\n",
    "y_pred[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a1ac",
   "metadata": {},
   "source": [
    "## Exercise: Write Your Confusion Matrix\n",
    "\n",
    "It is a common practice to summarize the performance of a model in a *confusion matrix*,\n",
    "containing the true positives and negatives found by our model on the testing data, as well as \n",
    "the false positives and negatives.\n",
    "\n",
    "In the case of binary classification, a confusion matrix is shaped as below.\n",
    "$$\n",
    "\\begin{array}{c|c|c}\n",
    "\\text{Actual / Predicted} & \\text{Positive} & \\text{Negative} \\\\ \\hline\n",
    "\\text{Positive} & TP & FN \\\\\n",
    "\\text{Negative} & FP & TN\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Among the many, three important measures can be obtained by the matrix above: accuracy, precision and recall.\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{TP + TN }{TP + FP + TN +FN}$$\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "$$\\text{Recall} = \\frac{TP}{TP + NP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19486189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{String}:\n",
       " \"versicolor\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"versicolor\"\n",
       " \"versicolor\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "874bd8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusion_matrix"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return a confusion matrix where rows encode the true labels, and columns encode the predicted\n",
    "values.\n",
    "\"\"\"\n",
    "function confusion_matrix(y_true, y_pred; labels=[\"versicolor\", \"virginica\", \"setosa\"])\n",
    "    if length(y_true) != length(y_pred)\n",
    "        throw(ArgumentError(\"Length mismatch ($(length(y_true)), $(length(y_pred)))\"))\n",
    "    end\n",
    "\n",
    "    nof_labels = length(labels)\n",
    "\n",
    "    string_to_idx = Dict{String, Int}()\n",
    "    for (i, label) in enumerate(labels)\n",
    "        string_to_idx[label] = i\n",
    "    end\n",
    "\n",
    "    cmatrix = zeros(Int, nof_labels, nof_labels)\n",
    "\n",
    "    for (true_value, predicted_value) in zip(y_true, y_pred)\n",
    "        cmatrix[string_to_idx[true_value], string_to_idx[predicted_value]] += 1\n",
    "    end\n",
    "\n",
    "    return cmatrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "526bb40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Int64}:\n",
       " 13  0  0\n",
       "  2  7  0\n",
       "  0  0  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9006a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "\"\"\"\n",
    "Return the accuracy of `m`.\n",
    "\"\"\"\n",
    "function accuracy(m::Matrix{Int})\n",
    "    # an efficient implementation of the confusion matrix, this would have been preprocessed\n",
    "    return sum(diag(m)) / sum(m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a90ee51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the average precision of all the classes embodied within `m`.\n",
    "\"\"\"\n",
    "function precision(m::Matrix{Int})\n",
    "    nrows = size(m, 1)\n",
    "    precisions = zeros(Float64, nrows)\n",
    "\n",
    "    for i in 1:nrows\n",
    "        true_positives = m[i,i]\n",
    "        false_positives = sum(m[i, :]) - true_positives        \n",
    "\n",
    "        precisions[i] = true_positives / (false_positives + true_positives)\n",
    "    end\n",
    "    \n",
    "    return sum(precisions) / nrows\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5ade4d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the average recall of all the classes embodied within `m`.\n",
    "\"\"\"\n",
    "function recall(m::Matrix{Int})\n",
    "    nrows = size(m, 1)\n",
    "    recalls = zeros(Float64, nrows)\n",
    "\n",
    "    for i in 1:nrows\n",
    "        true_positives = m[i,i]\n",
    "        false_negatives = sum(m[:, i]) - true_positives\n",
    "        \n",
    "        recalls[i] = true_positives / (false_negatives + true_positives)\n",
    "    end\n",
    "\n",
    "    return sum(recalls) / nrows\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa0d80",
   "metadata": {},
   "source": [
    "We can aggregate the (macro averaged) precision and recall together, via an harmonic mean.\n",
    "In the jargon, this new measure is called *F1 score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "125d9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1score"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the F1 score, with respect to the given `precision` and `recall`.\n",
    "\"\"\"\n",
    "function f1score(precision::Float64, recall::Float64)\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "88e1e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9259259259259259\n",
      "Recall: 0.9555555555555556\n",
      "F1 Score: 0.9405074365704288\n"
     ]
    }
   ],
   "source": [
    "_accuracy = accuracy(m)\n",
    "_precision = precision(m)\n",
    "_recall = recall(m)\n",
    "_f1score = f1score(_precision, _recall)\n",
    "\n",
    "println(\"Accuracy: $(_accuracy)\")\n",
    "println(\"Precision: $(_precision)\")\n",
    "println(\"Recall: $(_recall)\")\n",
    "println(\"F1 Score: $(_f1score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c1157",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning\n",
    "\n",
    "The arguments of `DecisionTreeClassifier(...)` are said to be `hyperparameters`, as they are the meta-parameters exploited for creating a specific algorithm (i.e., the if-else cascade we call decision tree).\n",
    "\n",
    "Which combination of hyperparameters should we provide?\n",
    "\n",
    "In this rather lightweight example, we can systematically try many combinations and keep the one which expresses the highest performances.\n",
    "\n",
    "This technique goes under the name of *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32902591",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 5, 7]\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "min_samples_split = [2, 4]\n",
    "\n",
    "best_score = 0.0\n",
    "best_params = nothing\n",
    "best_model = nothing\n",
    "\n",
    "for (_max_depth, _min_samples_leaf, _min_samples_split) in Iterators.product(\n",
    "    max_depths, min_samples_leaf, min_samples_split)\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth = 5,\n",
    "        min_samples_leaf = 1,\n",
    "        min_samples_split = 2\n",
    "    )\n",
    "\n",
    "    fit!(model, X_train', y_train)\n",
    "   \n",
    "    \n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220232f",
   "metadata": {},
   "source": [
    "# Learning with Sole.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28ead308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: see Day1-Appetizer.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.8",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
