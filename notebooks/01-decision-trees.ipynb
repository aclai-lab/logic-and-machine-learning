{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b819ec",
   "metadata": {},
   "source": [
    "# Classical Machine Learning Pipeline\n",
    "\n",
    "This section describes a classical machine learning pipeline.\n",
    "\n",
    "We leverage [MLUtils](https://github.com/JuliaML/MLUtils.jl), among the other things, for loading the data to play with, that is, the `iris` dataset.\n",
    "\n",
    "We partition the data into a set of *instances* `X` and the corresponding *labels* `y`. Each instance is one element of the cartesian product between the domains of the *attributes*.\n",
    "\n",
    "We want to find a relation between the instance space (i.e., many examples of iris flower) and the label space (i.e., the exact family to which each flower belongs). \n",
    "\n",
    "What we are going to do is train a (classification) decision tree, leveraging the `DecisionTree` library. \n",
    "\n",
    "Later in the notebook, we will repeat the process but leveraging `Sole.jl` library, and more-than-propositional logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197bfde",
   "metadata": {},
   "source": [
    "## Data Loading and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "06522de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], [\"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\"  …  \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\"], [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MLJBase\n",
    "\n",
    "X, y, attributes = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9ca6ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{String}:\n",
       " \"Sepal length\"\n",
       " \"Sepal width\"\n",
       " \"Petal length\"\n",
       " \"Petal width\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a5f9fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "500b76a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c45dce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 5.843333333333335\n",
       " 3.057333333333334\n",
       " 3.7580000000000027\n",
       " 1.199333333333334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2af98436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 0.8280661279778629\n",
       " 0.435866284936698\n",
       " 1.7652982332594664\n",
       " 0.7622376689603465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "473c4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 4.3\n",
       " 2.0\n",
       " 1.0\n",
       " 0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minimum(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "74d331d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 7.9\n",
       " 4.4\n",
       " 6.9\n",
       " 2.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maximum(X, dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ac52333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa - 50\n",
      "versicolor - 50\n",
      "virginica - 50\n"
     ]
    }
   ],
   "source": [
    "for class in unique(y)\n",
    "    println(\"$(class) - $(count(yi -> yi == class, y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77c324",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In the limited scenario of this exercise, there is not much space for complex preprocessing of our data. For example, we are not dealing with unbalanced classes, missing data and complex encodings. \n",
    "\n",
    "In the cell below, we partition the data into a training and a testing bucket, keeping a balanced class diversity.\n",
    "\n",
    "With this distinction, we can train a model on the initial training data and leverage the testing one for simulating a real-world scenario, obtaining reliable performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "566968c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "Random.seed!(1605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e2ae99c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.0 6.1 … 5.9 5.7; 3.4 3.0 … 3.2 3.0; 4.5 4.9 … 4.8 4.2; 1.6 1.8 … 1.8 1.2], [\"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"setosa\", \"versicolor\", \"setosa\", \"versicolor\", \"setosa\"  …  \"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"setosa\", \"setosa\", \"versicolor\", \"versicolor\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at the next cell; do you see why we need to shuffle our instances here?\n",
    "Xs, ys = shuffleobs((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d01acdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([6.0 6.1 … 5.1 6.7; 3.4 3.0 … 3.5 3.1; 4.5 4.9 … 1.4 5.6; 1.6 1.8 … 0.3 2.4], [\"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"setosa\", \"versicolor\", \"setosa\", \"versicolor\", \"setosa\"  …  \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"virginica\", \"setosa\", \"virginica\"]), ([6.1 4.4 … 5.9 5.7; 3.0 2.9 … 3.2 3.0; 4.6 1.4 … 4.8 4.2; 1.4 0.2 … 1.8 1.2], [\"versicolor\", \"setosa\", \"virginica\", \"versicolor\", \"virginica\", \"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"setosa\"  …  \"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"setosa\", \"setosa\", \"versicolor\", \"versicolor\"]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data, testing_data = splitobs((Xs, ys); at = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eb0c99d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.1 4.4 … 5.9 5.7; 3.0 2.9 … 3.2 3.0; 4.6 1.4 … 4.8 4.2; 1.4 0.2 … 1.8 1.2], [\"versicolor\", \"setosa\", \"virginica\", \"versicolor\", \"virginica\", \"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"setosa\"  …  \"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\", \"setosa\", \"setosa\", \"versicolor\", \"versicolor\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = training_data\n",
    "X_test, y_test  = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c4ec6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4c7799ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "aef71b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e2a7910a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                5\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [\"setosa\", \"versicolor\", \"virginica\"]\n",
       "root:                     Decision Tree\n",
       "Leaves: 7\n",
       "Depth:  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DecisionTree\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth = 5,\n",
    "    min_samples_leaf = 1,\n",
    "    min_samples_split = 2\n",
    ")\n",
    "\n",
    "fit!(model, X_train', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a3f6b",
   "metadata": {},
   "source": [
    "When printing a decision tree with `DecisionTree.print_tree`, the $N \\setminus M$ to the right of a leaf $l$\n",
    "encodes the fact that $N$ instances respects all the condition from the root of the tree to $l$ and, among those, $M$ are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "09f5dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 4 < 0.8 ?\n",
      "├─ setosa : 41/41\n",
      "└─ Feature 4 < 1.75 ?\n",
      "    ├─ Feature 3 < 4.95 ?\n",
      "        ├─ Feature 4 < 1.65 ?\n",
      "            ├─ versicolor : 38/38\n",
      "            └─ virginica : 1/1\n",
      "        └─ Feature 4 < 1.55 ?\n",
      "            ├─ virginica : 3/3\n",
      "            └─ Feature 1 < 6.95 ?\n",
      "                ├─ versicolor : 2/2\n",
      "                └─ virginica : 1/1\n",
      "    └─ virginica : 34/34\n"
     ]
    }
   ],
   "source": [
    "print_tree(model) # use print_tree(model, N) to limit the depth of the printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "89cc5388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{String}:\n",
       " \"versicolor\"\n",
       " \"setosa\"\n",
       " \"virginica\"\n",
       " \"versicolor\"\n",
       " \"virginica\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "y_pred = predict(model, X_test')\n",
    "y_pred[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a1ac",
   "metadata": {},
   "source": [
    "## Exercise: Write Your Confusion Matrix\n",
    "\n",
    "It is a common practice to summarize the performance of a model in a *confusion matrix*,\n",
    "containing the true positives and negatives found by our model on the testing data, as well as \n",
    "the false positives and negatives.\n",
    "\n",
    "In the case of binary classification, a confusion matrix is shaped as follows.\n",
    "$$\n",
    "\\begin{array}{c|c|c}\n",
    "\\text{Actual / Predicted} & \\text{Positive} & \\text{Negative} \\\\ \\hline\n",
    "\\text{Positive} & TP & FN \\\\\n",
    "\\text{Negative} & FP & TN\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Among the many, three important measures can be obtained by the matrix above: accuracy, precision, and recall.\n",
    "In the binary classification scenario, they are defined as follows.\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{TP + TN }{TP + FP + TN +FN}$$\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "$$\\text{Recall} = \\frac{TP}{TP + NP}$$\n",
    "\n",
    "In the multi-class scenario, as in our case, we can compute precision or recall individually for each class.\n",
    "For obtaining a unique scalar, we can average all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "19486189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{String}:\n",
       " \"versicolor\"\n",
       " \"setosa\"\n",
       " \"virginica\"\n",
       " \"versicolor\"\n",
       " \"virginica\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "874bd8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusion_matrix"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return a confusion matrix where rows encode the true labels, and columns encode the predicted\n",
    "values.\n",
    "\"\"\"\n",
    "function confusion_matrix(y_true, y_pred; labels=[\"versicolor\", \"virginica\", \"setosa\"])\n",
    "    if length(y_true) != length(y_pred)\n",
    "        throw(ArgumentError(\"Length mismatch ($(length(y_true)), $(length(y_pred)))\"))\n",
    "    end\n",
    "\n",
    "    nof_labels = length(labels)\n",
    "\n",
    "    string_to_idx = Dict{String, Int}()\n",
    "    for (i, label) in enumerate(labels)\n",
    "        string_to_idx[label] = i\n",
    "    end\n",
    "\n",
    "    cmatrix = zeros(Int, nof_labels, nof_labels)\n",
    "\n",
    "    for (true_value, predicted_value) in zip(y_true, y_pred)\n",
    "        cmatrix[string_to_idx[true_value], string_to_idx[predicted_value]] += 1\n",
    "    end\n",
    "\n",
    "    return cmatrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "526bb40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Int64}:\n",
       " 9   1  0\n",
       " 0  11  0\n",
       " 0   0  9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmatrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9006a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra: diag\n",
    "\n",
    "\"\"\"\n",
    "Return the accuracy of `m`.\n",
    "\"\"\"\n",
    "function accuracy(cmatrix::Matrix{Int})\n",
    "    # an efficient implementation of the confusion matrix, this would have been preprocessed\n",
    "    return sum(diag(cmatrix)) / sum(cmatrix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a90ee51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the average precision of all the classes embodied within `m`.\n",
    "\"\"\"\n",
    "function precision(cmatrix::Matrix{Int})\n",
    "    nrows = size(cmatrix, 1)\n",
    "    precisions = zeros(Float64, nrows)\n",
    "\n",
    "    for i in 1:nrows\n",
    "        true_positives = cmatrix[i,i]\n",
    "        false_positives = sum(cmatrix[i, :]) - true_positives        \n",
    "\n",
    "        precisions[i] = true_positives / (false_positives + true_positives)\n",
    "    end\n",
    "    \n",
    "    return sum(precisions) / nrows\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5ade4d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the average recall of all the classes embodied within `m`.\n",
    "\"\"\"\n",
    "function recall(cmatrix::Matrix{Int})\n",
    "    nrows = size(cmatrix, 1)\n",
    "    recalls = zeros(Float64, nrows)\n",
    "\n",
    "    for i in 1:nrows\n",
    "        true_positives = cmatrix[i,i]\n",
    "        false_negatives = sum(cmatrix[:, i]) - true_positives\n",
    "        \n",
    "        recalls[i] = true_positives / (false_negatives + true_positives)\n",
    "    end\n",
    "\n",
    "    return sum(recalls) / nrows\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa0d80",
   "metadata": {},
   "source": [
    "We can aggregate the (macro averaged) precision and recall together, via an harmonic mean.\n",
    "In the jargon, this new measure is called *F1 score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "125d9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1score (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute the F1 score.\n",
    "\"\"\"\n",
    "function f1score(cmatrix::Matrix{Int64})\n",
    "    return f1score(precision(cmatrix), recall(cmatrix))\n",
    "end\n",
    "function f1score(precision::Float64, recall::Float64)\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "88e1e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9259259259259259\n",
      "Recall: 0.9555555555555556\n",
      "F1 Score: 0.9405074365704288\n"
     ]
    }
   ],
   "source": [
    "_accuracy = accuracy(m)\n",
    "_precision = precision(m)\n",
    "_recall = recall(m)\n",
    "_f1score = f1score(_precision, _recall)\n",
    "\n",
    "println(\"Accuracy: $(_accuracy)\")\n",
    "println(\"Precision: $(_precision)\")\n",
    "println(\"Recall: $(_recall)\")\n",
    "println(\"F1 Score: $(_f1score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c1157",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning\n",
    "\n",
    "The arguments of `DecisionTreeClassifier(...)` are said to be `hyperparameters`, as they are the meta-parameters exploited for creating a specific algorithm (i.e., the if-else cascade we call decision tree).\n",
    "\n",
    "Which combination of hyperparameters should we provide?\n",
    "\n",
    "In this rather lightweight example, we can systematically try many combinations and keep the one which expresses the highest performances.\n",
    "\n",
    "This technique goes under the name of *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "32902591",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 5, 7]\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "min_samples_split = [2, 4]\n",
    "\n",
    "best_score = 0.0\n",
    "best_params = nothing\n",
    "best_model = nothing\n",
    "\n",
    "for (_max_depth, _min_samples_leaf, _min_samples_split) in Iterators.product(\n",
    "    max_depths, min_samples_leaf, min_samples_split)\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth = 5,\n",
    "        min_samples_leaf = 1,\n",
    "        min_samples_split = 2\n",
    "    )\n",
    "\n",
    "    fit!(model, X_train', y_train)\n",
    "   \n",
    "    y_pred = predict(model, X_test')\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    score = f1score(cm)\n",
    "\n",
    "    if score > best_score\n",
    "        best_score = score\n",
    "        best_params = ((_max_depth, _min_samples_leaf, _min_samples_split))\n",
    "        best_model = model\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "76d23cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameterization: (3, 1, 2)\n",
      "Corresponding F1 score: 0.9694364851957975\n"
     ]
    }
   ],
   "source": [
    "println(\"Best parameterization: $(best_params)\")\n",
    "println(\"Corresponding F1 score: $(best_score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220232f",
   "metadata": {},
   "source": [
    "# Learning with Sole.jl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbd1e3",
   "metadata": {},
   "source": [
    "## Tabular Datasets and Logisets\n",
    "\n",
    "Symbolic AI treats tabular datasets, such as the iris flower, as sets of propositional interpretations, onto which formulas of propositional logic are interpreted.\n",
    "\n",
    "Look at this classical tabular dataset $\\mathcal{I}$ below. We indicate instances with $I$, and *variables*$^{[1]}$, as $V_i$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    " & V_1 & V_2 & V_3 \\\\ \\hline\n",
    "I_1 & 1.2 & [1,2,3] & \\text{A} \\\\\n",
    "I_2 & 1.3 & [9,7,6] & \\text{B} \\\\\n",
    "I_3 & 0.8 & [2,8,2] & \\text{C} \\\\\n",
    "I_4 & 1.1 & [1,3,7] & \\text{B} \\\\\n",
    "I_5 & 1.2 & [4,3,3] & \\text{B} \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can change the point of view on the table above, from a statistical to a logical one, called *logiset*.\n",
    "\n",
    "This induction requires the definition of a propositional alphabet $\\mathcal{P}$.\n",
    "\n",
    "Consider $\\mathcal{P} = \\{p, q, r\\}$, with: \n",
    "\n",
    "$$p \\coloneqq \\text{max}(V_1) \\geq 1$$\n",
    "$$q \\coloneqq \\text{sum}(V_2) < 13$$\n",
    "$$r \\coloneqq V_3 = \\text{B}$$\n",
    "\n",
    "We indicate the truth constant with $\\top$ (top), and the falsehood with $\\bot$ (bot).\n",
    "\n",
    "The resulting logiset $\\mathcal{I}_\\mathcal{P}$ is this one:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    " & p & q & r \\\\ \\hline\n",
    "I_1 & \\top & \\top & \\bot \\\\\n",
    "I_2 & \\top & \\bot & \\top \\\\\n",
    "I_3 & \\bot & \\top & \\bot \\\\\n",
    "I_4 & \\top & \\top & \\top \\\\\n",
    "I_5 & \\top & \\top & \\top \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$^{[1]}$ We use the term \"variable\" to indicate, in general, a column of the tabular dataset: it could encode a raw attribute or a *feature* (a processed attribute).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "28ead308",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SoleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ae494044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropositionalLogiset (6.17 KBs)\n",
       "├ # instances:                  150\n",
       "├ # features:                   5\n",
       "└ Table: (sepal_length = [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0, 7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9], sepal_width = [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3, 3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0], petal_length = [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.5, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1, 6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1], petal_width = [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8], target = CategoricalArrays.CategoricalValue{String, UInt32}[\"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"versicolor\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\"])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = PropositionalLogiset(MLJBase.load_iris())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087dc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.8",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
