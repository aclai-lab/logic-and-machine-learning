{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03378f9",
   "metadata": {},
   "source": [
    "# Learning with non-classical Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "Pkg.instantiate()\n",
    "Pkg.status()\n",
    "Pkg.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "Random.seed!(1605)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1b6d3",
   "metadata": {},
   "source": [
    "## Learning with Modal Logic\n",
    "\n",
    "Let us try to tackle the Natops dataset with what we learned in the previous days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ARFFFiles\n",
    "\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using Plots\n",
    "using Random\n",
    "using StatsBase\n",
    "using SoleData\n",
    "using SoleModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2405abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_natops(arffstring::String)\n",
    "    df = DataFrame()\n",
    "    classes = String[]\n",
    "\n",
    "    lines = split(arffstring, \"\\n\")\n",
    "    for i in 1:length(lines)\n",
    "        line = lines[i]\n",
    "        \n",
    "        # split the current line;\n",
    "        # if it is not a data line, starting with DATA_MARK, continue;\n",
    "        # continue even in the case where checking the first character throwed out an error.\n",
    "        sline = nothing\n",
    "        try\n",
    "            sline = split(line, \" \")\n",
    "            if sline[1][1] != '\\''\n",
    "                continue\n",
    "            end\n",
    "        catch\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        # skip the initial hypen an read the data\n",
    "        sline[1] = sline[1][2:end]\n",
    "        data_and_class = split(sline[1], \"\\'\")\n",
    "        string_data = split(data_and_class[1], \"\\\\n\")\n",
    "        class = data_and_class[2][2:end]\n",
    "\n",
    "        if isempty(names(df))\n",
    "            for i in 1:length(string_data)\n",
    "                insertcols!(df, Symbol(\"V$(i)\") => Array{Float64, 1}[])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        float_data = Dict{Int,Vector{Float64}}()\n",
    "\n",
    "        for i in 1:length(string_data)\n",
    "            float_data[i] = map(x->parse(Float64,x), split(string_data[i], \",\"))\n",
    "        end\n",
    "\n",
    "        push!(df, [float_data[i] for i in 1:length(string_data)])\n",
    "        push!(classes, class)\n",
    "            \n",
    "    end    \n",
    "    \n",
    "    p = sortperm(eachrow(df), by=x->classes[rownumber(x)])\n",
    "\n",
    "    return df[p, :], classes[p]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b24e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read(joinpath(@__DIR__, \"..\", \"datasets\", \"natops.arff\"), String) |> parse_natops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variablenames = [\n",
    "    \"X[Hand tip l]\", \"Y[Hand tip l]\", \"Z[Hand tip l]\",\n",
    "    \"X[Hand tip r]\", \"Y[Hand tip r]\", \"Z[Hand tip r]\", \n",
    "    \"X[Elbow l]\", \"Y[Elbow l]\", \"Z[Elbow l]\",\n",
    "    \"X[Elbow r]\", \"Y[Elbow r]\", \"Z[Elbow r]\",\n",
    "    \"X[Wrist l]\", \"Y[Wrist l]\", \"Z[Wrist l]\",\n",
    "    \"X[Wrist r]\", \"Y[Wrist r]\", \"Z[Wrist r]\",\n",
    "    \"X[Thumb l]\", \"Y[Thumb l]\", \"Z[Thumb l]\",\n",
    "    \"X[Thumb r]\", \"Y[Thumb r]\", \"Z[Thumb r]\",\n",
    "]\n",
    "\n",
    "classnames = [\n",
    "    \"I have command\", \"All clear\", \"Not clear\", \"Spread wings\", \"Fold wings\", \"Lock wings\"]\n",
    "\n",
    "try\n",
    "    X = map(i -> variablenames[round(Int, parse(Float64, i))], X)\n",
    "    y = map(i -> classnames[round(Int, parse(Float64, i))], y)\n",
    "catch\n",
    "    println(\"You already converted the variable and class names to human readable strings.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ninstances, X_nattributes = size(X)\n",
    "X_ndatapoints = length(X[1,1])\n",
    "\n",
    "println(\"Number of instances: $(X_ninstances)\")\n",
    "println(\"Number of attributes: $(X_nattributes)\")\n",
    "println(\"Number of datapoints for each attribute: $(X_ndatapoints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every combination of instance and attributes,\n",
    "# we are still dealing with the same number of datapoints (51)\n",
    "all(\n",
    "    i -> length(X[i[1],i[2]]) == X_ndatapoints, \n",
    "    Iterators.product(1:X_ninstances, 1:X_nattributes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to change the target attribute\n",
    "_attribute = 4\n",
    "plot(X[1,_attribute], label = names(X)[_attribute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d983f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e196ad",
   "metadata": {},
   "outputs": [],
   "source": [
    " # let us summarize one instance for each class\n",
    "plot(map(i -> \n",
    "    plot(collect(X[i,:]), \n",
    "        labels=nothing,\n",
    "        title=y[i]), \n",
    "        1:30:180\n",
    "    )..., \n",
    "    layout = (2, 3), \n",
    "    size = (1500,400)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04711756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of X[hand tip l] of the first instance \n",
    "length(X[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02329f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each instance can be shaped as a Kripke Frame, whose worlds encode all the intervals \n",
    "# in the range [1, 51] (including the degenerate, punctual cases such as [1, 1])\n",
    "fr = SoleLogics.frame(X, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allworlds(fr) |> collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SoleLogics: Interval\n",
    "\n",
    "# enumerate the intervals that are \"Later\" than [1,10]\n",
    "collect(accessibles(fr, Interval(1,10), IA_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b43e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the value of a certain feature on each world where we can\n",
    "feature = SoleData.VariableMax(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X[1, 4], labels=\"X Hand tip right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SoleData.featvalue(feature, X, 1, Interval(10, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we are interested in windowing the data, it is easy to transform a dataset into a \n",
    "# Kripke Model\n",
    "Xk = scalarlogiset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca370b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check custom conditions over the logiset we just created\n",
    "p = Atom(ScalarCondition(feature, <, 1.0))\n",
    "check(p, Xk, 1, Interval(10, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(collect(X[1, 4:6]), labels=[\"V4 (X right hand)\" \"V5 (Y right hand)\" \"V6 (Z right hand)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Atom(ScalarCondition(VariableMin(4), >, 1.0))\n",
    "q = Atom(ScalarCondition(VariableMax(5), <=, 3.0))\n",
    "r = Atom(ScalarCondition(VariableMax(6), <=, 0.0))\n",
    "\n",
    "phi = ¬p ∨ (q ∧ r)\n",
    "println(syntaxstring(phi))\n",
    "\n",
    "check(phi, SoleLogics.LogicalInstance(Xk, 1), Interval(10, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c924ffb",
   "metadata": {},
   "source": [
    "Let us try to check some modal formulae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxlater = box(SoleLogics.IA_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "later_always_phi = boxlater(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(later_always_phi, SoleLogics.LogicalInstance(Xk, 1), Interval(10, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "SoleLogics.getinstance(Xk, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40196d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us try with an even more complex scenario\n",
    "check_mask = zeros(Int64, 51)\n",
    "for i in 1:X_ndatapoints\n",
    "    check_mask[i] = check(phi, SoleLogics.LogicalInstance(Xk, i), Interval(1,30))\n",
    "end\n",
    "\n",
    "println(check_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630493a9",
   "metadata": {},
   "source": [
    "### Modal Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SoleBase\n",
    "using ModalDecisionTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fcea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the experiment we are just going to execute could be too \n",
    "# heavy for standard commodity hardware;\n",
    "# we can reduce data dimensionality via a moving window\n",
    "X_small = broadcast(x -> movingwindow(mean, x; nwindows = 10, relative_overlap = 0.2), X)\n",
    "\n",
    "X_small_ninstances, X_small_nattributes = size(X_small)\n",
    "X_small_ndatapoints = length(X_small[1,1])\n",
    "\n",
    "println(\"The number of datapoints changed from $(X_ndatapoints) to $(X_small_ndatapoints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7435cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [maximum, minimum]\n",
    "Xk_small = scalarlogiset(X_small, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3048481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModalDecisionTree(; relations = :IA, features = [minimum, maximum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dca23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_small_train, X_small_test), (y_small_train, y_small_test) = partition(\n",
    "    (X_small, y), 0.7, rng=121, shuffle=true, multi=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c32fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind the modal decision tree to the logiset;\n",
    "# then train it and compute the accuracy\n",
    "\n",
    "mach = machine(model, X_small_train, y_small_train)\n",
    "@time fit!(mach);\n",
    "\n",
    "y_small_predict_probabilities = MLJ.predict(mach, X_small_test)\n",
    "y_small_predict = mode.(y_small_predict_probabilities)\n",
    "\n",
    "MLJ.accuracy(y_small_predict, y_small_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the restricted modal decision tree learned\n",
    "printmodel(report(mach).rawmodel_full; hidemodality = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show its *pure* version\n",
    "printmodel(report(mach).solemodel_full; show_metrics = true, hidemodality = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_restricted_tree = ModalDecisionTrees.prune(\n",
    "    report(mach).rawmodel_full; simplify = true)\n",
    "\n",
    "puretree = ModalDecisionTrees.translate(simplified_restricted_tree)\n",
    "printmodel(\n",
    "    puretree; \n",
    "    threshold_digits = 2, \n",
    "    use_feature_abbreviations = true, \n",
    "    parenthesize_atoms = false, \n",
    "    variable_names_map = [names(X)], \n",
    "    hidemodality = true\n",
    ")\n",
    "\n",
    "println(\"# Leaves: \", SoleModels.nsubmodels(puretree))\n",
    "println(\"# Classes: \", length(unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the leaf rules and their training performances\n",
    "ruleset = listrules(puretree)\n",
    "printmodel.(\n",
    "    ruleset; \n",
    "    show_metrics = true, \n",
    "    threshold_digits = 2, \n",
    "    use_feature_abbreviations = true, \n",
    "    parenthesize_atoms = false, \n",
    "    hidemodality = true\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ff7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"IF\\n\\t\", \n",
    "    SoleLogics.experimentals.formula2natlang(\n",
    "        antecedent(ruleset[4]);\n",
    "        threshold_digits = 2,\n",
    "        variable_names_map = [names(X)]\n",
    "    )\n",
    ")\n",
    "\n",
    "println(\"THEN\\n\\t\", consequent(ruleset[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752af48",
   "metadata": {},
   "source": [
    "### Modal Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea3fe4",
   "metadata": {},
   "source": [
    "Now, we follow an *unsupervised* approach, ignoring the class label.\n",
    "\n",
    "The hypothesis here, is that a logical formula is *interesting*, if it happens \n",
    "to be frequently satisfied across all the instances of a dataset $\\mathcal{I}$.\n",
    "\n",
    "Given an alphabet $\\mathcal{P}$ of propositional literals, the formula we are dealing with\n",
    "are literal conjunctions called *itemsets*.\n",
    "\n",
    "An itemset that is also frequent is called *frequent itemset*.\n",
    "\n",
    "More formally, given a dataset $\\mathcal{I}$, a propositional alphabet $\\mathcal{P}$\n",
    "and a minimum threshold $s$, a frequent pattern $\\mathsf{P} \\subseteq \\mathcal{P}$ is such that:\n",
    "\n",
    "$$\\text{support}(\\mathcal{I}, \\mathsf{P}) = \\frac{| \\{I \\in \\mathcal{I} \\mid I \\models \\mathsf{P} \\} |}{|\\mathcal{I}|} \\geq s$$\n",
    "\n",
    "The ratio above is called *support*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1913c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModalAssociationRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are just three toy atoms\n",
    "p = Atom(ScalarCondition(VariableMax(4), >=, 2)) |> Item\n",
    "q = Atom(ScalarCondition(VariableMin(5), <=, 1.5)) |> Item\n",
    "r = Atom(ScalarCondition(VariableMax(6), >=, 0.0)) |> Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Itemset encodes a conjunction of SoleLogics.Formula, but has two advantages:\n",
    "\n",
    "# 1) performance considerations that really suit the field of association rule mining \n",
    "# https://towardsdev.com/set-vs-vector-lookup-in-julia-a-closer-look-9d106d01ccae\n",
    "\n",
    "# 2) they prevent type piracy!\n",
    "\n",
    "pq = Itemset([p, q])\n",
    "pr = Itemset([p, r])\n",
    "qr = Itemset([q, r])\n",
    "pqr = Itemset([p, q, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Itemset can wrap any SoleLogics.Formula type;\n",
    "# it prevent \n",
    "formula(pq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ad784",
   "metadata": {},
   "source": [
    "##### Exercise:\n",
    "Define your own `mysupport` function.\n",
    "\n",
    "Its argument must be of type `SoleLogics.Formula`, `SoleData.AbstractLogiset` and `SoleLogics.AbstractWorld`.\n",
    "\n",
    "We only want to consider the instances that were originally associated with the `I have command` class.\n",
    "\n",
    "We want to treat the Kripke model as a degenerate propositional logiset.\n",
    "\n",
    "Then compute the support of the following itemsets: `p`, `q`, `r`, `p ∧ q`, `p ∧ r`, `r ∧ q`, `p ∧ q ∧ r`. \n",
    "\n",
    "The support must be rounded to the second decimal digit.\n",
    "\n",
    "Solution (Base64):\n",
    "ZnVuY3Rpb24gbXlzdXBwb3J0KHBoaTo6RiwgWGs6OkwsIHdvcmxkOjpXKSB3aGVyZSB7CiAgICBGPDpTb2xlTG9naWNzLkZvcm11bGEsIAogICAgTDw6U29sZURhdGEuQWJzdHJhY3RMb2dpc2V0LCAKICAgIFc8OlNvbGVMb2dpY3MuQWJzdHJhY3RXb3JsZAp9CiAgICAKICAgIF9uaW5zdGFuY2VzID0gbmluc3RhbmNlcyhYaykKCiAgICBjaGVja19tYXNrID0gemVyb3MoSW50OCwgX25pbnN0YW5jZXMpCgogICAgQGluYm91bmRzIEBzaW1kIGZvciBpIGluIDE6X25pbnN0YW5jZXMgCiAgICAgICAgY2hlY2tfbWFza1tpXSA9IGNoZWNrKHBoaSwgWGssIGksIHdvcmxkKQogICAgZW5kCgogICAgcmV0dXJuIHJvdW5kKG1lYW4oY2hlY2tfbWFzayk7IGRpZ2l0cyA9IDIpCmVuZA=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9288f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your definition here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try\n",
    "    for phi in [p, q, r, pq, pr, qr, pqr]\n",
    "        println(\n",
    "            mysupport(formula(phi), SoleData.slicedataset(Xk, 1:30), Interval(1, X_ndatapoints)))\n",
    "    end\n",
    "catch e\n",
    "    if e isa UndefVarError\n",
    "        println(\"You need to implement mysupport.\")\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19cb45",
   "metadata": {},
   "source": [
    "Let us consider an alphabet of propositional literals $\\mathcal{P}$, and let us suppose that \n",
    "$\\mathsf{P} \\subseteq \\mathcal{P}$ is a frequent pattern we found.\n",
    "\n",
    "We can partition $\\mathsf{P}$ in two smaller frequent patterns, $\\mathsf{Q}, \\mathsf{R}$, such that $\\mathsf{Q} \\cap \\mathsf{R} = \\emptyset$.\n",
    "\n",
    "We denote with $\\mathsf{Q} \\Rightarrow \\mathsf{R}$ the fact that an *interesting* statistical relation occurs between the antecedent and the consequent: if this is the case, then we have an *association rule*.\n",
    "\n",
    "Similarly to the case of frequent patterns, the interestingness must be established with specific measures, which are called *meaningfulness measures* in the jargon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware of the difference between an Item (such as p) and an Itemset;\n",
    "# we need to cast p to Itemset, even if it is a trivial 1-length Itemset.\n",
    "println(typeof(p))\n",
    "ARule(Itemset(p), qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try\n",
    "    ARule(pq, qr)\n",
    "catch e \n",
    "    if e isa ArgumentError\n",
    "        println(\"Beware: pq ∩ qr is not empty.\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6071d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ARule(Itemset(p), qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModalAssociationRules.antecedent(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModalAssociationRules.consequent(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f235e8",
   "metadata": {},
   "source": [
    "##### Quiz\n",
    "\n",
    "Try to explain the ratio below, which is commonly called *confidence*.\n",
    "\n",
    "$$\\text{confidence}(\\mathcal{I}, \\mathsf{P} \\Rightarrow \\mathsf{Q}) = \\frac{\\text{support}(\\mathcal{I}, \\mathsf{P} \\cap \\mathsf{Q})}{\\text{support}(\\mathcal{I}, \\mathsf{P})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d11f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the generator Itemset back\n",
    "Itemset(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad810c0",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "\n",
    "Implement your own `myconfidence` function.\n",
    "\n",
    "Solution (Base 64):\n",
    "ZnVuY3Rpb24gbXljb25maWRlbmNlKHJ1bGU6OkFSdWxlLCBYazo6TCwgd29ybGQ6OlcpIHdoZXJlIHsKICAgIEw8OlNvbGVEYXRhLkFic3RyYWN0TG9naXNldCwgCiAgICBXPDpTb2xlTG9naWNzLkFic3RyYWN0V29ybGQKfQogICAgZnVsbF9mb3JtdWxhID0gZm9ybXVsYShJdGVtc2V0KHJ1bGUpKQogICAgYW50ZWNlZGVudF9mb3JtdWxhID0gZm9ybXVsYShNb2RhbEFzc29jaWF0aW9uUnVsZXMuYW50ZWNlZGVudChydWxlKSkKCiAgICByZXR1cm4gbXlzdXBwb3J0KGZ1bGxfZm9ybXVsYSwgWGssIHdvcmxkKSAvIG15c3VwcG9ydChhbnRlY2VkZW50X2Zvcm11bGEsIFhrLCB3b3JsZCkgCmVuZA=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ca265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae329f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try\n",
    "    for phi in [p, q, r, pq, pr, qr, pqr]\n",
    "        println(\n",
    "            myconfidence(rule, SoleData.slicedataset(Xk, 1:30), Interval(1, X_ndatapoints)))\n",
    "    end\n",
    "catch e\n",
    "    if e isa UndefVarError\n",
    "        println(\"You need to implement myconfidence.\")\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704432f",
   "metadata": {},
   "source": [
    "##### Enhancing Modal Association Rules with Modalities\n",
    "\n",
    "When dealing with Kripke models, a natural dichotomy pops up!\n",
    "\n",
    "Let us consider an alphabet of modal literals $\\Lambda_\\mathcal{P}$, obtained by enriching a standard,\n",
    "propositional alphabet $\\mathcal{P}$ with modal operators.\n",
    "\n",
    "Let us also consider a modal dataset $\\mathcal{I}$ and an instance $I = (W,R,v) \\in \\mathcal{I}$ in it, \n",
    "as well as a pattern $\\mathsf{P}$.\n",
    "\n",
    "We can assess the interestingness of $\\mathsf{P}$ within an instance by computing its *local support*, and comparing it \n",
    "with respect to a *minimum local support threshold* $s_l$.\n",
    "\n",
    "$$\\text{lsupport}(I, \\mathsf{P}) = \\frac{ |\\{w \\in W \\mid I, w \\models \\mathsf{P} \\}| }{|\\mathcal{W}|}$$\n",
    "\n",
    "The other part of the dichotomy, that is, the notion of *global* support, is left as an exercise (see the Quiz below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cec12c",
   "metadata": {},
   "source": [
    "##### Quiz\n",
    "How would you aggregate many local support computations, to compute a *global* support?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09777f63",
   "metadata": {},
   "source": [
    "##### Mining Association Rules from Time Series Items\n",
    "\n",
    "We want to probe our instances with considerations on the shape of the signal in a certain interval, for a given feature.\n",
    "\n",
    "We also want to increase the expressiveness of the result association rules with the help of `HS` logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcaa84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _normalize(x::Vector{R}) where {R <: Real}\n",
    "    eps = 1e-10\n",
    "    return (x .- mean(x)) ./ (std(x) + eps)\n",
    "end\n",
    "\n",
    "function zeuclidean(x::Vector{R}, y::Vector{R}) where {R}\n",
    "    # normalize x and y\n",
    "    meanx = mean(x)\n",
    "    meany = mean(y)\n",
    "\n",
    "    # avoid division by zero\n",
    "    eps = 1e-10\n",
    "\n",
    "    x_z = _normalize(x)\n",
    "    y_z = _normalize(y)\n",
    "\n",
    "    # z-normalized euclidean distance formula\n",
    "    return sqrt(sum((x_z .- y_z).^2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e14ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only right hand and right elbow\n",
    "varids = vcat(collect(4:6), collect(10:12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_res_path = joinpath(@__DIR__, \"..\", \"res\", \"natops-for-mar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57907a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization\n",
    "\n",
    "function load_motifs(filepath, save_filename_prefix)\n",
    "    ids = [id for id in deserialize(joinpath(filepath, \"$(save_filename_prefix)-ids\"))];\n",
    "    motifs = [m for m in deserialize(joinpath(filepath, \"$(save_filename_prefix)-motifs\"))];\n",
    "    featurenames = [f for f in deserialize(joinpath(filepath, \"$(save_filename_prefix)-featurenames\"))];\n",
    "    return ids, motifs, featurenames\n",
    "end\n",
    "\n",
    "\n",
    "ids, motifs, featurenames = load_motifs(mar_res_path, \"NATOPS-IHCC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f83de",
   "metadata": {},
   "source": [
    "In this example, we only consider intervals of length 10 and 20.\n",
    "\n",
    "In particular, given a world encoding an interval of such length, we compute the (normalized)\n",
    "euclidean distance between it and a pool of particular time series, called \"motifs\".\n",
    "\n",
    "If the distance is low enough, then it means that the gesture encoded by the motif is happening.\n",
    "\n",
    "Try to browse the motifs we are playing with, by tweaking the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plot(motifs[i], label = \"V$(ids[i]) $(featurenames[i])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11204d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    SoleData.VariableDistance(id, m, distance=zeuclidean, featurename=name)\n",
    "    for (id, m, name) in zip(ids, motifs, featurenames)\n",
    "]\n",
    "\n",
    "syntaxstring.(variables)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only consider the instances related to the \"I have command\" class;\n",
    "# we are not cheating: in this unsupervised setting, we just want to describe them\n",
    "IHCC = reduce(vcat, [X[1:30, :], X[(180+1):(180+30), :]]);\n",
    "IHCCk = scalarlogiset(IHCC, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "propositionalatoms = [\n",
    "    Atom(ScalarCondition(v, <=, 1.0))\n",
    "    for v in variables\n",
    "]\n",
    "\n",
    "syntaxstring.(propositionalatoms)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4eb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = Vector{Item}(\n",
    "    reduce(vcat, [\n",
    "        propositionalatoms,\n",
    "        diamond(IA_A).(propositionalatoms),\n",
    "        diamond(IA_B).(propositionalatoms),\n",
    "        diamond(IA_E).(propositionalatoms),\n",
    "        diamond(IA_D).(propositionalatoms),\n",
    "        diamond(IA_O).(propositionalatoms),\n",
    "    ])\n",
    ")\n",
    "\n",
    "syntaxstring.(atoms)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f02859",
   "metadata": {},
   "outputs": [],
   "source": [
    "_items = Vector{Item}(atoms);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a25aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "miner = Miner(\n",
    "    # the data from which we want to find all the frequent itemsets\n",
    "    IHCCk,\n",
    "\n",
    "    # the strategy we want to leverage for exploring the frequent itemset space\n",
    "    apriori,\n",
    "\n",
    "    # the initial alphabet of facts\n",
    "    _items,\n",
    "\n",
    "    # the interestingness measures for the frequent itemsets\n",
    "    [(gsupport, 0.1, 0.1)],\n",
    "\n",
    "    # the meaningfulness measures for the association rules\n",
    "    [(gconfidence, 0.5, 0.5)];\n",
    "    \n",
    "    worldfilter=SoleLogics.FunctionalWorldFilter(\n",
    "        x -> (length(x) == 10) || (length(x) == 20), Interval{Int}\n",
    "    ),\n",
    "\n",
    "    itemset_policies=Function[\n",
    "        isanchored_itemset(ignoreuntillength=1),\n",
    "        isdimensionally_coherent_itemset()\n",
    "    ],\n",
    "\n",
    "    arule_policies=Function[\n",
    "        islimited_length_arule(consequent_maxlength=3),\n",
    "        isanchored_arule()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfe85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine!(miner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49409dd8",
   "metadata": {},
   "source": [
    "## Learning with Many-Valued Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa6ac6",
   "metadata": {},
   "source": [
    "### Many-Expert Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24135d71",
   "metadata": {},
   "source": [
    "`ManyExpertDecisionTrees.jl` is still in development and has not been released\n",
    "yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ManyExpertDecisionTrees\n",
    "using ManyExpertDecisionTrees: build_tree, prune_tree, FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SoleLogics.ManyValuedLogics\n",
    "\n",
    "allexperts = (GodelLogic, LukasiewiczLogic, ProductLogic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Combinatorics\n",
    "\n",
    "# Compute all possible expert compbinations (with replacement)\n",
    "expertcomb = begin\n",
    "    c = Vector{Vector{FuzzyLogic}}()\n",
    "    for i in 1:length(allexperts)\n",
    "        append!(c, collect(Combinatorics.with_replacement_combinations(allexperts, i)))\n",
    "    end\n",
    "    c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa59f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets # used to load the iris dataset\n",
    "\n",
    "\n",
    "data = RDatasets.dataset(\"datasets\", \"iris\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b72f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful to read results later \n",
    "expertcombreadable = map(expertcomb) do experts\n",
    "    result = \"\"\n",
    "    for expert in experts\n",
    "        if (expert === GodelLogic)\n",
    "            result *= \"G\"\n",
    "        end\n",
    "        if (expert === LukasiewiczLogic)\n",
    "            result *= \"L\"\n",
    "        end\n",
    "        if (expert === ProductLogic)\n",
    "            result *= \"P\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b03d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [[0.0, 0.0] for _ in 1:length(expertcomb)];\n",
    "wrong = [[0.0, 0.0] for _ in 1:length(expertcomb)];\n",
    "vague = [[0.0, 0.0] for _ in 1:length(expertcomb)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec24141",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = begin\n",
    "    X = data[:, 1:end-1]\n",
    "    y = data[:, size(data, 2)]\n",
    "    X, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "for i in 1:n_runs\n",
    "    # Partition set into training and validation\n",
    "    X_train, y_train, X_test, y_test = begin\n",
    "        train, test = partition(eachindex(y), 0.8, shuffle=true, rng=i)\n",
    "        X_train, y_train = X[train, :], y[train]\n",
    "        X_test, y_test = X[test, :], y[test]\n",
    "        X_train, y_train, X_test, y_test\n",
    "    end\n",
    "\n",
    "    # Build a standard decision tree\n",
    "    dt = build_tree(y_train, Matrix(X_train))\n",
    "    dt = prune_tree(dt, 0.9)\n",
    "\n",
    "    # For each expert combination, build a ManyExpertDecisionTree \n",
    "    Threads.@threads for k in eachindex(expertcomb)\n",
    "        mf_experts = ntuple(_ -> FL.GaussianMF, length(expertcomb[k]))\n",
    "        MXA = ManyExpertAlgebra(expertcomb[k]...)\n",
    "\n",
    "        medt = manify(dt, X_train, mf_experts...)\n",
    "\n",
    "        y_pred = map(eachrow(X_test)) do row\n",
    "            result = ManyExpertDecisionTrees.apply(\n",
    "                medt,\n",
    "                MXA,\n",
    "                Vector{Float64}(row)\n",
    "            )\n",
    "            return length(result) != 1 ? :vague : first(result)\n",
    "        end\n",
    "\n",
    "        # Extrapolating statistics\n",
    "        n_total = length(y_test)\n",
    "\n",
    "        n_vague = count(==(:vague), y_pred)\n",
    "        pvague = (n_vague / n_total) * 100\n",
    "\n",
    "        n_correct = count(i -> y_pred[i] == y_test[i], 1:n_total)\n",
    "        pcorrect = (n_correct / n_total) * 100\n",
    "\n",
    "        n_wrong = n_total - n_correct - n_vague\n",
    "        pwrong = (n_wrong / n_total) * 100\n",
    "\n",
    "        deltacorrect = (pcorrect - correct[k][1])\n",
    "        correct[k][1] += deltacorrect / i\n",
    "        correct[k][2] += deltacorrect * (pcorrect - correct[k][1])\n",
    "\n",
    "        deltawrong = (pwrong - wrong[k][1])\n",
    "        wrong[k][1] += deltawrong / i\n",
    "        wrong[k][2] += deltawrong * (pwrong - wrong[k][1])\n",
    "\n",
    "        deltavague = (pvague - vague[k][1])\n",
    "        vague[k][1] += deltavague / i\n",
    "        vague[k][2] += deltavague * (pvague - vague[k][1])\n",
    "\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bfb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results: extract means and compute standard deviations (sample std)\n",
    "correct_mean = [x[1] for x in correct]\n",
    "correct_std = [sqrt(x[2] / (n_runs - 1)) for x in correct]\n",
    "\n",
    "wrong_mean = [x[1] for x in wrong]\n",
    "wrong_std = [sqrt(x[2] / (n_runs - 1)) for x in wrong]\n",
    "\n",
    "vague_mean = [x[1] for x in vague]\n",
    "vague_std = [sqrt(x[2] / (n_runs - 1)) for x in vague]\n",
    "\n",
    "df = DataFrame(\n",
    "    experts=expertcombreadable,\n",
    "    correct_mean=correct_mean,\n",
    "    correct_std=correct_std,\n",
    "    wrong_mean=wrong_mean,\n",
    "    wrong_std=wrong_std,\n",
    "    vague_mean=vague_mean,\n",
    "    vague_std=vague_std\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.8",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
