{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b819ec",
   "metadata": {},
   "source": [
    "# Symbolic Machine Learning\n",
    "\n",
    "The main way-to-go for implementing a machine learning pipeline in Julia is via\n",
    "the [MLJ.jl](https://juliaai.github.io/MLJ.jl/stable/) package.\n",
    "\n",
    "We are going to work with the `iris` dataset, trying to discover the relation \n",
    "between the specific attribute values of an iris flower and the family to which\n",
    "the same flower belongs to.\n",
    "\n",
    "More generally, we want to find the relation between the values of the\n",
    "*attributes* of each instance (`X`) and the corresponding *labels* (`y`). \n",
    "\n",
    "In order to do so, we are going to train a (classification) decision tree,\n",
    "leveraging the `DecisionTree` package, which can be easily integrated within an\n",
    "`MLJ` pipeline.\n",
    "\n",
    "Later in this notebook, we will repeat this process leveraging the `Sole.jl`\n",
    "library, which will allow us to explicitly model the problem through the lens of\n",
    "logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "Pkg.instantiate()\n",
    "Pkg.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility purposes\n",
    "using Random\n",
    "Random.seed!(1605)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82903ca6",
   "metadata": {},
   "source": [
    "## Learning with MLJ.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197bfde",
   "metadata": {},
   "source": [
    "### Data Loading and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06522de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using RDatasets # used to load the iris dataset\n",
    "\n",
    "\n",
    "data = RDatasets.dataset(\"datasets\", \"iris\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e509e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(data, ==(:Species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical vectors are lighter than raw vectors; can you guess why?\n",
    "typeof(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure that classes are balanced\n",
    "for class in unique(y)\n",
    "    println(\"$(class) - $(count(yi -> yi == class, y))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77c324",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "In the limited scenario of this exercise, there is not much space for complex\n",
    "preprocessing of our data. For example, we are not dealing with unbalanced\n",
    "classes, missing data, or complex encodings. \n",
    "\n",
    "The usual workflow, at this point, is to partition the data into a training and\n",
    "a test bucket, keeping a balanced class diversity.\n",
    "\n",
    "With this distinction, we can train a model on the initial training data and\n",
    "leverage the test one for simulating a real-world scenario, obtaining reliable\n",
    "performance.\n",
    "\n",
    "MLJ makes our work *much* easier, even providing us with a more sophisticated\n",
    "training strategy, as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0cd658",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "We will integrate an external model, coming from the `DecisionTree` package,\n",
    "into the MLJ workflow.\n",
    "\n",
    "In the next lessons, we will be doing something similar with another model\n",
    "called `ModalDecisionTree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try\n",
    "    DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n",
    "catch\n",
    "    println(\"The DecisionTreeClassifier symbol has already been imported.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLJDecisionTreeInterface.DecisionTreeClassifier(\n",
    "    max_depth=5, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c26f0",
   "metadata": {},
   "source": [
    "A machine is a binding between a model and the data it works with.\n",
    "\n",
    "It also keeps track of other information we might want to inspect, such as the\n",
    "specific parameters learned by a model.\n",
    "\n",
    "In the cell below, we bind the decision tree model to all the instances we have\n",
    "available. This is not a good idea, but we will return on the topic in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abcb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_probabilities = MLJ.predict(mach, X)\n",
    "y_predict = mode.(y_predict_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params(mach).tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f303602",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Overfitting \n",
    "\n",
    "It is common practice to summarize the performance of a model using a\n",
    "*confusion matrix*, containing the true positives and negatives found by our\n",
    "model on the test data, as well as the false positives and negatives.\n",
    "\n",
    "In the case of binary classification, a confusion matrix is shaped as follows.\n",
    "$$\n",
    "\\begin{array}{c|c|c}\n",
    "\\text{Predicted / Ground truth} & \\text{Positive} & \\text{Negative} \\\\ \\hline\n",
    "\\text{Positive} & TP & FN \\\\\n",
    "\\text{Negative} & FP & TN\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Among the many, three important measures can be obtained by the matrix above:\n",
    "accuracy, precision, and recall.\n",
    "In the binary classification scenario, they are defined as follows.\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN +FN}$$\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "In the multi-class scenario, as in our case, we can compute precision and recall\n",
    "individually for each class. For obtaining a unique scalar, we can average all\n",
    "the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa720f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wow! our model is so good!\n",
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb190b2",
   "metadata": {},
   "source": [
    "How awful! The model we just trained is bad, for sure.\n",
    "\n",
    "Can you tell why?\n",
    "\n",
    "Answer (decode from [base64encode](https://www.base64encode.org/)): `VGhlIGNvZGUgaXMgbm90IGdlbmVyYWxpemluZyEKVGhlIHNwbGl0cyBpbiB0aGUgdHJlZXMganVzdCBiZWNvbWUgYSBzdHJhdGVneSBmb3IgbWVtb3JpemluZyAoYW5kIGNvbXByZXNzaW5nKSB0aGUgZ2l2ZW4gZGF0YS4KUmVtZW1iZXI6IGFuIGludGVsbGlnZW50IGJlaGF2aW91ciBhbHdheXMgc3RlbXMgZnJvbSBnZW5lcmFsaXphdGlvbiBjYXBhYmlsaXRpZXMu`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee54198",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb6087",
   "metadata": {},
   "source": [
    "Imagine projecting the data points on a bidimensional plane: can you provide a graphical sketch \n",
    "of what is happening during the inference process of the tree trained above? \n",
    "\n",
    "Let us to obtain a more reliable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test), (y_train, y_test) = partition((X, y), 0.7, rng=121, shuffle=true, multi=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(model, X_train, y_train)\n",
    "fit!(mach)\n",
    "y_predict_probabilities = MLJ.predict(mach, X_test)\n",
    "y_predict = mode.(y_predict_probabilities)\n",
    "cm = confusion_matrix(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751ea0e",
   "metadata": {},
   "source": [
    "We can iterate the process above on multiple *folds*, to assess the overall quality of a \n",
    "machine learning training strategy. This technique is commonly called *cross-validation*.\n",
    "\n",
    "In the following, the iris dataset will be shuffled and divided into training and test in \n",
    "different ways, and each time a decision tree will be learned and tested over a different\n",
    "portion of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate!(\n",
    "    mach,\n",
    "    resampling=StratifiedCV(; nfolds = 5, shuffle=true),    # cross validation\n",
    "    measures=[accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c1157",
   "metadata": {},
   "source": [
    "### Training with Hyperparameters Tuning\n",
    "\n",
    "The arguments of `DecisionTreeClassifier(...)` are said to be `hyperparameters`,\n",
    "as they are the meta-parameters exploited for creating a specific algorithm\n",
    "(i.e., the if-else cascade we call decision tree).\n",
    "\n",
    "Which combination of hyperparameters should we provide?\n",
    "\n",
    "In this rather lightweight example, we can systematically try many combinations\n",
    "and keep the one which expresses the highest performance.\n",
    "\n",
    "This technique goes under the name of *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(Int, :max_depth, lower=2, upper=10)\n",
    "min_samples_leaf_range = range(Int, :min_samples_leaf, lower=1, upper=5)\n",
    "min_samples_split_range = range(Int, :min_samples_split, lower=2, upper=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32902591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_tree = TunedModel(\n",
    "    model = MLJDecisionTreeInterface.DecisionTreeClassifier(),\n",
    "    resampling = StratifiedCV(nfolds = 5, shuffle = true),\n",
    "    range = [max_depth_range, min_samples_leaf_range, min_samples_split_range],\n",
    "    measure = accuracy,\n",
    "    tuning = Grid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model, exploring different hyperparameterizations with cross validation\n",
    "mach = machine(tuned_tree, X, y)\n",
    "fit!(mach)\n",
    "y_predict_probabilities = MLJ.predict(mach, X_test)\n",
    "y_predict = mode.(y_predict_probabilities)\n",
    "cm = confusion_matrix(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220232f",
   "metadata": {},
   "source": [
    "## Learning with Sole.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbd1e3",
   "metadata": {},
   "source": [
    "### Tabular Datasets and Logisets\n",
    "\n",
    "Symbolic AI treats tabular datasets, such as the iris flower, as sets of\n",
    "propositional interpretations, onto which formulas of propositional logic are\n",
    "interpreted.\n",
    "\n",
    "Look at the (classical) tabular dataset $\\mathcal{I}$ below. We denote instances\n",
    "with $I$, and *variables*$^{[1]}$, as $V_i$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    " & V_1 & V_2 & V_3 \\\\ \\hline\n",
    "I_1 & 1.2 & [1,2,3] & \\text{A} \\\\\n",
    "I_2 & 1.3 & [9,7,6] & \\text{B} \\\\\n",
    "I_3 & 0.8 & [2,8,2] & \\text{C} \\\\\n",
    "I_4 & 1.1 & [1,3,7] & \\text{B} \\\\\n",
    "I_5 & 1.2 & [4,3,3] & \\text{B} \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can change the point of view on the table above from a statistical to a\n",
    "logical one, called a *logiset*.\n",
    "\n",
    "This requires the definition of a propositional alphabet $\\mathcal{P}$.\n",
    "\n",
    "Consider $\\mathcal{P} = \\{p, q, r\\}$, with: \n",
    "\n",
    "$$p \\coloneqq V_1 \\geq 1$$\n",
    "$$q \\coloneqq \\text{sum}(V_2) < 13$$\n",
    "$$r \\coloneqq V_3 = \\text{B}$$\n",
    "\n",
    "We denote the truth constant with $\\top$ (top), and the false constant with\n",
    "$\\bot$ (bot).\n",
    "\n",
    "The resulting (propositional) logiset $\\mathcal{I}_\\mathcal{P}$ is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    " & p & q & r \\\\ \\hline\n",
    "I_1 & \\top & \\top & \\bot \\\\\n",
    "I_2 & \\top & \\bot & \\top \\\\\n",
    "I_3 & \\bot & \\top & \\bot \\\\\n",
    "I_4 & \\top & \\top & \\top \\\\\n",
    "I_5 & \\top & \\top & \\top \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$^{[1]}$ We use the term \"variable\" to denote, in general, a column of the\n",
    "tabular dataset: this corresponds to a raw attribute or a *feature* (a processed\n",
    "attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ead308",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJBase\n",
    "using SoleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae494044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logiset = PropositionalLogiset(data);\n",
    "X_logiset.tabulardataset == data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = parseformula(\n",
    "    \"SepalLength > 5.8 âˆ§ SepalWidth < 3.0 âˆ¨ Species == \\\"setosa\\\"\";\n",
    "    atom_parser = a->Atom(parsecondition(SoleData.ScalarCondition, a; featuretype = SoleData.VariableValue)),\n",
    "    # TODO: this should prevent the warning below, but the dispatch is caught by SoleLogics\n",
    "    # featvaltype = Real,\n",
    "    # featuretype = SoleData.VarFeature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(phi, SoleLogics.LogicalInstance(X_logiset, 1))\n",
    "check(phi, X_logiset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb09a5",
   "metadata": {},
   "source": [
    "### From DecisionTree.jl to SoleModels.jl\n",
    "\n",
    "If we manage to make an existing model compliant with the interface of `SoleModels` package, then we can play with it from a logical standpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SoleModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(model, X_train, y_train)\n",
    "fit!(mach)\n",
    "\n",
    "# \\:seedling:\n",
    "ðŸŒ± = fitted_params(mach).tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we encode the model in such a way that it can be investigated via SoleModels\n",
    "# \\:evergreen_tree:\n",
    "ðŸŒ² = solemodel(ðŸŒ±)\n",
    "printmodel(ðŸŒ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5076a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all the logical rules encoded by the tree\n",
    "listrules(ðŸŒ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricstable(ðŸŒ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the testing instances to the tree, and compare the metrics\n",
    "# with the testing samples\n",
    "apply!(ðŸŒ², X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21473b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can visualize how our model behaved at testing time \n",
    "metricstable(\n",
    "    ðŸŒ²; \n",
    "    normalize = true, \n",
    "    metrics_kwargs = (; \n",
    "        additional_metrics = (; \n",
    "            height = r->SoleLogics.height(antecedent(r))\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join some rules for the same class into a single, sufficient and necessary \n",
    "# condition for the same class\n",
    "metricstable(joinrules(ðŸŒ²; min_ncovered = 1, normalize = true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2e5d3",
   "metadata": {},
   "source": [
    "Here, we are just scratching the surface of Sole framework, limiting ourselves to pretty \n",
    "printings.\n",
    "\n",
    "In the next lessons, we will enhance the machine learning pipeline we introduced today,\n",
    "with spatial reasoning considerations.\n",
    "\n",
    "Below, there is a little spoiler about a fancy machine learning model, which is general enough\n",
    "for dealing with more-than-propositional logics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModalDecisionTrees\n",
    "\n",
    "mdt_model = ModalDecisionTree()\n",
    "mach = machine(mdt_model, X_test, y_test)\n",
    "fit!(mach)\n",
    "y_pred = predict_mode(mach)\n",
    "cm = confusion_matrix(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747a0c5",
   "metadata": {},
   "source": [
    "### Extracting logical rules using SolePostHoc.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SolePostHoc\n",
    "\n",
    "lumen(ðŸŒ²)\n",
    "# batrees(nomemodello)\n",
    "# rulecosiplus(nomemodello)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.8",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
